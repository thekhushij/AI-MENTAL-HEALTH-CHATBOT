{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQNGtHdU6OJS",
    "outputId": "44995e60-12c4-48b3-a71b-86bf6ebf87ba"
   },
   "outputs": [],
   "source": [
    "!pip install langchain_groq langchain_core langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXHOpaH46qNz",
    "outputId": "43cf38d4-e15a-4ba5-c754-06fb076ac219"
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    temperature = 0,\n",
    "    groq_api_key = \"\",\n",
    "    model_name = \"llama-3.3-70b-versatile\"\n",
    ")\n",
    "result = llm.invoke(\"Who is lord Ram?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EMrh3XG8oET",
    "outputId": "a6ea6cde-c697-48c2-a57f-3b59320538e3"
   },
   "outputs": [],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZC_k5J25_OPC",
    "outputId": "0b5fcf19-00c7-496d-f57a-2df7274cd161"
   },
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSTghfuaAMSW",
    "outputId": "24c9f479-5880-4487-fb14-3eda3c537275"
   },
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5d663e1a97d940f9a9121ee18375d79a",
      "b7358940845049859a04362d6b23f626",
      "1f3d96fdf66f4076be1dbb7b9b2fbe4d",
      "4664bf1d98af4dd1aff770ce74d8b418",
      "f333e90c16954c0e98b5df7510be254e",
      "712c51478b3f45a48b437509fa1986a9",
      "ba8bc9bc80f54974812e7f786282ef07",
      "2803ba62e73b417090934c80a1f147b3",
      "4f2d241109f142eabb072bb7bfb4466d",
      "e31fae8cfe084fefbc620c1a4dccb05e",
      "bf35fa07c9df482097742d73c1bc3525",
      "9da5c805bf954f5f846cbefeb8c9fb55",
      "baff57f78e434beb9cbe2acd9b833ce0",
      "6eb14a07c04343beb629b0dcb386cba2",
      "49c583a5df9c4f5ab973f5eeb641bad4",
      "061ce1325038449f8d017d09bf4fefde",
      "c1e83e44dbac41a0af6725af012a6c57",
      "a3530b7c5d0444868aeb1568be997d0d",
      "0cdff126b5cb441f9941f62a56ecdf3d",
      "dd2bde9b871a42159961a90d848e5755",
      "8b6a98e8b4e3499ebfbe7a9d64bb1037",
      "4cc428a8cca9403db3e17c3c20e90958",
      "1099d450ec9a4e13bd70d120eed4209d",
      "952ab2b9fb9b46398f34899878c4e100",
      "457b437d213f4014bf3cbb66c668cb0a",
      "ae78e15445af4f3da0d4a93ac1521e6b",
      "acfd83be3c2e4bb8816d887f49041061",
      "e0b9e560f1004283b79b4d008e77a388",
      "2db1d3695d064e14af862969a43bc167",
      "fb1c0fa287214a4ea2bc3a1097f6f75f",
      "5b9703e9ca8643c3840e07b94a4e0690",
      "ddd06c447a6f49eaa7024efc481d2070",
      "3b62c429295c4bcaa449508b06b63ee5",
      "ee421031e5d24c5eb74e6d05b20a04f2",
      "01db9ad6ec6a4a68842936c6b7e04e77",
      "4a62d1ba94a244b18920352659400247",
      "57b7e4ce9fd84f4e8ae53c4d5480fff1",
      "fc173550b38b4ecf84814ba7050bdf42",
      "035670133b214ab1a3a8a39ade5122aa",
      "a21a7c66ee454932831e1765395f7bbd",
      "cbc0316097894c1b8d1e5b6beae38864",
      "04b3c5a0f8ba4282b87fba9050a75fee",
      "32dbf9271d5544379134d7589063d676",
      "63d953d206dd4643b670ed06258f367a",
      "a012b5c9ae2d4d8a8e5679ee69ac5584",
      "17a23cd74b954fb3bafda376ac4f36c0",
      "0c879e8a3eab4fc5805f0ad799e57445",
      "120e19d0da6c44cca0162bca05cbac81",
      "020831a0423847fb91f80f01a5bfaa7e",
      "1ee384ba13c44ea399d4b69907028cac",
      "24ec931607874ea69e76a1a2d1009fbc",
      "27e6cd0896284375a834f32a07ce0477",
      "76d3953cd4e246c58f3328a48bb32c2d",
      "545a18d0f52c41daa09cdb8b0d6cfb8c",
      "0a8325c4417b42e59f482776a2ddbbff",
      "906087b9ce2a4c6a97574aedd7f6acf1",
      "7dad0dfd392640a5861f3021045203ad",
      "fbc9b45c1645487ea568f346dec516b6",
      "01d8d0820af2449aba35e1350a80cc65",
      "6f4e5ff3924e4eb9be9e846fd01efd95",
      "b9778cc632ba4011b1565d096bbb2fe2",
      "e69252958b5e4500b37319ec0cbba24d",
      "0dfd911e21554fe5852e8e7fda4b9579",
      "284c39040a744f22b09824cd93e14809",
      "02f58f8036a6475e9202ac602f6d915c",
      "01d276a11df54d17b0ea2e86449d1a18",
      "1be0219988284b06b0047c9ac44b424b",
      "8dd658f07d07453ab7724e9cc8b5d897",
      "78683999fec542d28a5fdd180c3788b8",
      "73564bd2d37d4830ba9cf0cd05f62b1c",
      "407ea9cf8123478a8d0b2812652390fe",
      "fdbc40b985934242a604434f36d5af72",
      "a586e2e125924f7a83a037ee463baf3d",
      "b1732b7536604d06b37d604aa35c7391",
      "fbd7af9cfa6c4fd4a789d897fa5f0450",
      "9fc1a917aaf7472695702264856ed804",
      "a04fdaa6b2d646af808df4f9f3485caa",
      "04e865640e7f4179b92a54abfa6fecc9",
      "f54262cb30224bae8885773b62aad030",
      "273c06896b8c4bc4b41e0f431b14e460",
      "3cb8f1d74d2a4f668e2fe44f8ba5aaab",
      "1ebd19edaca3469e875f6e1f1798d6af",
      "313245ef12f44f149351186d5f9109ae",
      "d37bab994b234c669ba8d9ed51963cb4",
      "96af9c0d4562411e93b9f47f99b45859",
      "c20fe23094274d2eb21a90cb25f0ad95",
      "70d40d591ee24623a24d6cd7e092210b",
      "233394bc9e174a47813c130592c4234e",
      "2cab9e5eecc84f1a8aa66b56e0e8bad4",
      "1f3e4d09a92843cc9c3af96126c46621",
      "c5f829a2367641299e83c552ba6ffd6f",
      "f56c119622cc406297ea0def00206fb7",
      "11442c2361a04c8aa6e435e41afd33d7",
      "0dd5343e4be9450f8aba2a944cafb60d",
      "ce3e854b4ec94bdd80ab491e12578254",
      "e4242f466c324c8b82ccfd868c3f7613",
      "1a86652a69f84c4ca8fc73da36a7634b",
      "150833d583ad4aa88ec199a5a60c5889",
      "1ff481da82bd4b24af983144ee8e1859",
      "c477dd87d2ef43e18f668b22ab115e65",
      "485a8f15acec40e1be1327e6c2438efd",
      "14f5970d96ae4d05a9e3048274740329",
      "18e7bfe51fce42c1a677f1317eb5fb9d",
      "fe3ac9721d3b4287be1dba95e099a59a",
      "afc91bff7fc94a448b4d709c731bda6d",
      "b43ec5a418c2466fac21f2426268d6b6",
      "9aca243742a24603829fc05accf44620",
      "bba744947e3d48ffbea00032e786f7de",
      "29064532c9ac44dcb8e5007a6e691993",
      "db6bdf1822a24ba6b06692b6128c782c",
      "cf594e6864f4445599051c458ae5ca9e",
      "e2b0017860dd43c4bfc00488277bbcb5",
      "66ae94e34e514d33917bccb97f7533e8",
      "fca84c81ac544aeea1ad70731bbf26e4",
      "d832760ea3424d609068313f9d8c926b",
      "137e040200804f688ead34f238eeb9b1",
      "de55a7bef7b04b239ebf864e66e4b48b",
      "31794f9f745f4aa38052aad6a4ad05b9",
      "a103f3451d854784a52dca2f5846cb9a",
      "2b75a8b863654d14bb8ae0730af075ec",
      "136d93a8a663424d8772ca2fa301ddf4"
     ]
    },
    "id": "F-l2n0dE7Jj7",
    "outputId": "a006f8b6-f1a4-4cc8-b539-ed31c5112153"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "def initialize_llm():\n",
    "  llm = ChatGroq(\n",
    "    temperature = 0,\n",
    "    groq_api_key = \"\",\n",
    "    model_name = \"llama-3.3-70b-versatile\"\n",
    ")\n",
    "  return llm\n",
    "\n",
    "def create_vector_db():\n",
    "  loader = DirectoryLoader(\"/content/data/\", glob = '*.pdf', loader_cls = PyPDFLoader)\n",
    "  documents = loader.load()\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 50)\n",
    "  texts = text_splitter.split_documents(documents)\n",
    "  embeddings = HuggingFaceBgeEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "  vector_db = Chroma.from_documents(texts, embeddings, persist_directory = './chroma_db')\n",
    "  vector_db.persist()\n",
    "\n",
    "  print(\"ChromaDB created and data saved\")\n",
    "\n",
    "  return vector_db\n",
    "\n",
    "def setup_qa_chain(vector_db, llm):\n",
    "  retriever = vector_db.as_retriever()\n",
    "  prompt_templates = \"\"\" You are a compassionate mental health chatbot. Respond thoughtfully to the following question:\n",
    "    {context}\n",
    "    User: {question}\n",
    "    Chatbot: \"\"\"\n",
    "  PROMPT = PromptTemplate(template = prompt_templates, input_variables = ['context', 'question'])\n",
    "\n",
    "  qa_chain = RetrievalQA.from_chain_type(\n",
    "      llm = llm,\n",
    "      chain_type = \"stuff\",\n",
    "      retriever = retriever,\n",
    "      chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "  )\n",
    "  return qa_chain\n",
    "\n",
    "\n",
    "def main():\n",
    "  print(\"Intializing Chatbot.........\")\n",
    "  llm = initialize_llm()\n",
    "\n",
    "  db_path = \"/content/chroma_db\"\n",
    "\n",
    "  if not os.path.exists(db_path):\n",
    "    vector_db  = create_vector_db()\n",
    "  else:\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "  qa_chain = setup_qa_chain(vector_db, llm)\n",
    "\n",
    "  while True:\n",
    "    query = input(\"\\nHuman: \")\n",
    "    if query.lower()  == \"exit\":\n",
    "      print(\"Chatbot: Take Care of yourself, Goodbye!\")\n",
    "      break\n",
    "    response = qa_chain.run(query)\n",
    "    print(f\"Chatbot: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QMjfz9eIatW",
    "outputId": "f1400600-9970-4d86-c45a-6936e1002975"
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkmCcmB7IijJ",
    "outputId": "713889e0-7797-4d16-ed14-25db93891e25"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import gradio as gr\n",
    "def initialize_llm():\n",
    "  llm = ChatGroq(\n",
    "    temperature = 0,\n",
    "    groq_api_key = \"\",\n",
    "    model_name = \"llama-3.3-70b-versatile\"\n",
    ")\n",
    "  return llm\n",
    "\n",
    "def create_vector_db():\n",
    "  loader = DirectoryLoader(\"/content/data/\", glob = '*.pdf', loader_cls = PyPDFLoader)\n",
    "  documents = loader.load()\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 50)\n",
    "  texts = text_splitter.split_documents(documents)\n",
    "  embeddings = HuggingFaceBgeEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "  vector_db = Chroma.from_documents(texts, embeddings, persist_directory = './chroma_db')\n",
    "  vector_db.persist()\n",
    "\n",
    "  print(\"ChromaDB created and data saved\")\n",
    "\n",
    "  return vector_db\n",
    "\n",
    "def setup_qa_chain(vector_db, llm):\n",
    "  retriever = vector_db.as_retriever()\n",
    "  prompt_templates = \"\"\" You are a compassionate mental health chatbot. Respond thoughtfully to the following question:\n",
    "    {context}\n",
    "    User: {question}\n",
    "    Chatbot: \"\"\"\n",
    "  PROMPT = PromptTemplate(template = prompt_templates, input_variables = ['context', 'question'])\n",
    "\n",
    "  qa_chain = RetrievalQA.from_chain_type(\n",
    "      llm = llm,\n",
    "      chain_type = \"stuff\",\n",
    "      retriever = retriever,\n",
    "      chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "  )\n",
    "  return qa_chain\n",
    "\n",
    "\n",
    "print(\"Intializing Chatbot.........\")\n",
    "llm = initialize_llm()\n",
    "\n",
    "db_path = \"/content/chroma_db\"\n",
    "\n",
    "if not os.path.exists(db_path):\n",
    "  vector_db  = create_vector_db()\n",
    "else:\n",
    "  embeddings = HuggingFaceBgeEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "  vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "qa_chain = setup_qa_chain(vector_db, llm)\n",
    "\n",
    "def chatbot_response(user_input, history = []):\n",
    "  if not user_input.strip():\n",
    "    return \"Please provide a valid input\", history\n",
    "  response = qa_chain.run(user_input)\n",
    "  history.append((user_input, response))\n",
    "  return \"\", history\n",
    "\n",
    "with gr.Blocks(theme = 'Respair/Shiki@1.2.1') as app:\n",
    "    gr.Markdown(\"# ðŸ§  Mental Health Chatbot ðŸ¤–\")\n",
    "    gr.Markdown(\"A compassionate chatbot designed to assist with mental well-being. Please note: For serious concerns, contact a professional.\")\n",
    "\n",
    "    chatbot = gr.ChatInterface(fn=chatbot_response, title=\"Mental Health Chatbot\")\n",
    "\n",
    "    gr.Markdown(\"This chatbot provides general support. For urgent issues, seek help from licensed professionals.\")\n",
    "\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_BQRVGRJkEh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}